Deep learning has been remarkably successful in many areas~\cite{}. However, many studies find out deep learning methods are hard to generalize when they encounter an unseen domain, which has a different data distribution than domains used for training~\cite{}. This problem called \textit{domain shift}~\cite{}. For alleviating the domain shift problem, many studies have been carried out on different assumptions. Domain Adaptation (DA) assumes there are two domains~\cite{}. The first is a fully-labeled source domain, and the other is a sparsely labeled or totally unlabeled target domain. Otherwise, domain generalization (DG) assumes there are some fully-labeled source domains, but the target domain is totally unavailable. DG is a challenge but important research area because generalization to other domains is crucial to make a safe artificial intelligence. Moreover, it is helpful to understand how deep neural networks see the world.

Existing DG studies can be classified into several categories depending on their strategies. Some methods proposed novel model architectures that are robust to domain shift~\cite{}. Others suggested learning algorithms aim to induce a model to fit in a more robust minimum~\cite{}. The others adopted losses to learn domain-invariant features by matching feature distributions of the source domains~\cite{}. Although these domain-invariant feature learning methods work well, the methods are sub-optimal because they do not utilize task-specific information such as class labels explicitly. 

Our approach also aims to learn domain-invariant features, but the proposed method explicitly adopts the task-specific information. More specifically, we add a simple consistency loss that induces the model to produce similar features when the labels are the same. By doing this, the model is expected to learn features that are adequately semantic and constant across domains.

To demonstrate the proposed method works, we will conduct experiments on the standard DG benchmarks such as PACS~\cite{} or VLCS~\cite{}. Specifically, we will show the consistency loss is helpful to improve the performance of the baseline, which simply aggregates all the source domains and uses it as a training set. Then, we will show that the proposed method is comparable to or better than many previous works.

